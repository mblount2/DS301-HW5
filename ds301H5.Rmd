---
title: "DS 301 H5"
author: "Mikaela Blount"
date: "4/2/2020"
output:
  word_document: default
  html_document: default
---

Problem 1:
a)
π0 = 0.8
π1 = 0.2
P(X|Y=0) ~ N(2,3)
P(X|Y=1) ~ N(4,3)
mu0 = 2
mu1 = 4
sig^2 = 3

b)
d0(x) = 2x/3 - (4/6) + log(0.8) 
-2x/3 = -(4/6) + log(0.8) - d0(x)
x = -3/2(-(4/6) + log(0.8) - d0(x))

d1(x) = 4x/3 - 16/6 + log(0.8)
-4x/3 = -16/6 + log(0.8) - d1(x)
x = -3/4(-16/6 + log(0.8) - d1(x))

c)
```{r}
library(class)
library(MASS)

set.seed(11)
X0 = rnorm(800,2,sd=3)
mean(X0)
X1 = rnorm(200,4,sd=3)
mean(X1)
X_train = c(X0,X1)
Y_train = rep(c(0,1),c(800,200))
sigmaSquared = 1/(1000-2)*(800*var(X0)+200*var(X1))
sigmaSquared

set.seed(12)
X0_test = rnorm(800,2,sd=3)
X1_test = rnorm(200,4,sd=3)
Xtest = c(X0_test,X1_test)
Ytest = rep(c(0,1),c(800,200))

prob_y0 = 0.8*dnorm(X_train,2,sd=3)/(dnorm(X_train,2,sd=3)*0.8+dnorm(X_train,4,sd=3)*0.2)
prob_y1 = 0.2*dnorm(X_train,4,sd=3)/(dnorm(X_train,2,sd=3)*0.2+dnorm(X_train,4,sd=3)*0.8)
Y = rep(1,1000)
for(i in 1:1000){
	if(prob_y0[i]>prob_y1[i]){
		Y[i] = 0
	}
}
#bayes error rate
table(Y,Ytest)
mean(Y!=Ytest)

mean(prob_y0)
mean(prob_y1)
```
mu0 = 2.08667
mu1 = 3.785188
sigma^2 = 8.944863
π0 = 0.7996883
π1 = 0.1897487

d)
```{r}
data.train = as.data.frame(cbind(Y_train,X_train))
data.test = as.data.frame(cbind(Ytest,Xtest))
lda.fit = lda(Y_train~X_train,data=data.train)
lda.pred = predict(lda.fit,data.test)
lda.fit
t1 = table(lda.pred$class,Ytest)
mean(lda.pred$class!=Ytest)

```


e)
LDA = 0.2
Bayes = 0.199

f)
```{r}
X_train = as.matrix(X_train)
X_test = as.matrix(Xtest)
knn.pred = knn(X_train,X_test,Y_train,k=3) 
table(knn.pred,Ytest)
mean(knn.pred!=Ytest) 
```
Test error rate: 0.233

g) Both LDA (0.2) and KNN (0.233) have slightly higher test rate errors than Bayes (0.199).

h) I would recommend using LDA over KNN because it had a lower error rate (0.2 vs 0.233) meaning it LDA will correctly classify more than KNN.



Problem 2:
```{r}
library(dplyr)
spam <- read.csv("~/Downloads/spambase.data", header=FALSE)
spam = spam %>%
  rename(spamCol = V58)
```

a)
```{r}
spam$spamCol = as.numeric(spam$spamCol)

isSpam = spam %>%
  filter(spamCol == 1)

length(isSpam$spamCol)/length(spam$spamCol)*100

notSpam = spam %>%
  filter(spamCol == 0)

length(notSpam$spamCol)/length(spam$spamCol)*100
```
Spam: 39.40448%
Not spam: 60.59552%

b) I will spilt the dataset into spam and not spam, randomly arrange the rows, and then take 80% to train and 20% to test. I will full join the spam train and not spam and then do the same for spam test and not spam test thus preserving the correct ratios from above.
```{r}
set.seed(42)

rowsIsSpam <- sample(nrow(isSpam))
isSpamRandom <- isSpam[rowsIsSpam, ]
isSpamRandom = isSpamRandom %>%
  arrange()

len80percentIS = floor(nrow(isSpamRandom)*.8)
trainIsSpam = isSpamRandom[1:len80percentIS,]
testIsSpam = isSpamRandom[(len80percentIS+1):nrow(isSpamRandom),]

rowsNotSpam <- sample(nrow(notSpam))
notSpamRandom <- notSpam[rowsNotSpam, ]
notSpamRandom = notSpamRandom %>%
  arrange()

len80percentNS = floor(nrow(notSpamRandom)*.8)
trainNotSpam = notSpamRandom[1:len80percentNS,]
testNotSpam = isSpamRandom[(len80percentNS+1):nrow(notSpamRandom),]

train = full_join(trainIsSpam,trainNotSpam)
test = full_join(testIsSpam,testNotSpam)
```

c)
```{r}
train = na.omit(train)
test = na.omit(test)
  
X_train = train[,1:57]
Y_train = train[,58]
X_test = test[,1:57]
Y_test = test[,58]


#logistic
glm.train = glm(spamCol~.,data=train, family=binomial)

summary(glm.train)

coef(glm.train)

glm.probs = predict(glm.train,test,type='response')
head(glm.probs)

glm.pred = rep(0,nrow(test))
glm.pred[glm.probs>0.5] = 1 
table(glm.pred,test$spamCol)
mean(glm.pred==test$spamCol)
mean(glm.pred!=test$spamCol)

#lda
library(MASS)

lda.fit = lda(spamCol~.,data=train)

lda.pred = predict(lda.fit,test)
names(lda.pred)
head(lda.pred$class) # automatically assigns Y to the class with largest probability 
head(lda.pred$posterior)
#P(Y=0|X)
#P(Y=1|X)

t1 = table(lda.pred$class,Y_test)
mean(lda.pred$class!=Y_test)


#KNN

library(class)
X_train = as.matrix(X_train)
X_test = as.matrix(X_test)
knn.pred = knn(X_train,X_test,Y_train,k=1) 
table(knn.pred,Y_test)
mean(knn.pred!=Y_test) 

```
Logistic error rate = 0.1101928
LDA error rate = 0.2093664
KNN error rate = 0.2176309 (k=1 had lowest error rate)

e) I recommend using logistic regression because it had the lowest misclassification by far out of all 3.


Problem 3:
a) The misclassification rate is (25+32)/(25+32+40+121) = 0.2614679. It is worse to have a false negative because they person will not receive proper treatment and would spread the virus because they think they do not have the virus. We can change the posterior probability rate to change false negative rate and we would want to decrease the rate below 0.5 to decrease false negative.



b)
```{r}
library(ProbYX)

ydat = c(0,1,0,1,1) # red = 0, blue = 1
xdat = c(-2,5,-1,10,5)

MLEs(ydat = ydat,xdat = xdat,distr = "exp")
```
B0 = 1.960784
B1 = 0.85


c) KNN struggles with the curse of dimensionality. Having 10,000 predictors means that it will 10,000-dimensional so points that would be close in a 2-dimensional case are super far apart in a 10,000-dimensional case.

d)
  i. Logistic regression would be best because it is less resistant to outliers than LDA and the sample size is not large enough for KNN.
  
  ii. LDA would be best because it is large enough to classify better than logistic regression and it is not complex or non-linear enough for KNN to be best.
  
  iii. KNN would be best because KNN handles nonlinearity and complexity better than LDA or logistic regression.

e) LDA performs better than QDA when the groups are linear and there is constant variance. The model is less likely to be prone to underfitting (low variance, high bias) because the model is highly linear and has constant variance which LDA will capture better than QDA.

f) Since the groups are linear than the bayes decision boundary will be linear, QDA will perform better than LDA because QDA has more flexibility to form around that specific trainning data. This could lead to overfitting but since we are just concerned what will fit better for just the trainning data, QDA would be better.





